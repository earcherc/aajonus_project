{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6084335a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /Users/ethancavill/anaconda3/lib/python3.11/site-packages (from en-core-web-sm==3.5.0) (3.5.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/ethancavill/anaconda3/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/ethancavill/anaconda3/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/ethancavill/anaconda3/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.7)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/ethancavill/anaconda3/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.6)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/ethancavill/anaconda3/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.6)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /Users/ethancavill/anaconda3/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.12)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/ethancavill/anaconda3/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.9.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/ethancavill/anaconda3/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/ethancavill/anaconda3/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.10)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /Users/ethancavill/anaconda3/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.9.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /Users/ethancavill/anaconda3/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/ethancavill/anaconda3/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/ethancavill/anaconda3/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/ethancavill/anaconda3/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.24.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/ethancavill/anaconda3/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /Users/ethancavill/anaconda3/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.12)\n",
      "Requirement already satisfied: jinja2 in /Users/ethancavill/anaconda3/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /Users/ethancavill/anaconda3/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (68.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/ethancavill/anaconda3/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/ethancavill/anaconda3/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/ethancavill/anaconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ethancavill/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ethancavill/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ethancavill/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ethancavill/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2023.7.22)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/ethancavill/anaconda3/lib/python3.11/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/ethancavill/anaconda3/lib/python3.11/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.1.3)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/ethancavill/anaconda3/lib/python3.11/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/ethancavill/anaconda3/lib/python3.11/site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "spacy.cli.download(\"en_core_web_sm\")\n",
    "# python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e05e501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.pipeline.sentencizer.Sentencizer at 0x165ac4b10>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\", \"parser\"])\n",
    "nlp.add_pipe(\"sentencizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3eb4f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Needles_Of_Disease_and_Death_Continue_In_The_Name_Of_Saving_Children.txt\n",
      "Diarrhea-based_Detoxification_Hotel_By_Medical_Doctors.txt\n",
      "The_FDA_Approved_5_Viruses_for_Food_Treatment.txt\n",
      "Genius_Children.txt\n",
      "Dr._Stanley_S._Bass_Interview.txt\n",
      "Q&A_Of_September_13,_2009.txt\n",
      "Causes_For_Most_Intestinal_Disease.txt\n",
      "Are_Raw_Miso_And_Shoyu_Healthy_Sauces?.txt\n",
      "Safe_Cutting_Boards.txt\n",
      "Multiple_Lacerations_Healed_Without_Medical_Help.txt\n",
      "Cholesterol,_LDL_and_HDL.txt\n",
      "Primal_Diet_Workshop_+_Q&A_Of_May_6,_2000.txt\n",
      "Can_We_Preserve_Raw_Chicken_In_Vinegar_Or_Lemon_Juice?.txt\n",
      "Abrasions,_Fractures_and_Breaks.txt\n",
      "Is_Raw_Chocolate_Made_From_Whole_Raw_Cocoa_Beans_Addictive_Or_Harmful?.txt\n",
      "What_Is_Constipation_And_How_Do_We_Resolve_It?.txt\n",
      "Our_Ubiquitous_Microbial_Friends.txt\n",
      "Quinton.txt\n",
      "Q&A_Of_December_14,_2008.txt\n",
      "Q&A_Of_October_14,_2012.txt\n",
      "My_Survival_Kit.txt\n",
      "Medical_Propaganda_about_Inflammatory_Breast_Cancer.txt\n",
      "How_Are_Nutrients_Delivered_To_Our_Cells?.txt\n",
      "Q&A_Of_August_24,_2008.txt\n",
      "Vaccines_Ruin_Your_Health.txt\n",
      "Frozen_Pastured_Meat_VS_Fresh_Supermarket_Meat.txt\n",
      "Long-term_Damage_From_Abduction_and_Forced_Injections.txt\n",
      "Q&A_Of_May_26,_2013.txt\n",
      "FLU_-_Viral_Tools_Improve_Health.txt\n",
      "Email_from_Aajonus_Summer_2012.txt\n",
      "Dental_Hygiene,_Causes_of_Decay_and_Reversal,_and_Re-enamelization.txt\n",
      "Bad_And_Good_Parasites,_And_Malaria?.txt\n",
      "View_on_Medical_Establishment.txt\n",
      "Formula_for_a_Healthy_Baby.txt\n",
      "Top_Aussie_Doctor_Says_Pick_Your_Nose_And_Eat_it.txt\n",
      "Supplements.txt\n",
      "Primal_Diet_Workshop_(Part_1).txt\n",
      "Raw_Dairy_Is_Healthy_But_Illegal.txt\n",
      "Does_Rabies_Exist?.txt\n",
      "Q&A_Of_May_2,_2004.txt\n",
      "Abduction_and_Injections.txt\n",
      "Is_Raw_Milk_Always_Beneficial_Even_With_Much_Bacteria?.txt\n",
      "Q&A_Of_September_10,_2006.txt\n",
      "How_Long_Does_It_Take_To_Understand_The_Primal_Diet(TM)?.txt\n",
      "Rawesome_Trial_Outcome.txt\n",
      "Q&A_Of_June_29,_2008.txt\n",
      "Whole_Foods_Markets,_Inc._Friend_To_Better_Health_Or_Foe?.txt\n",
      "Q&A_Of_December_17,_2006.txt\n",
      "What_Should_We_Consider_For_Health_When_Buying_A_New_Car?.txt\n",
      "Q&A_Of_January_24,_1999.txt\n",
      "Lobbying_in_Washington,_DC_for_Raw_Milk.txt\n",
      "What_Do_We_Do_About_Emerging_Plagues?.txt\n",
      "Is_The_Science_of_Viruses_Real?.txt\n",
      "Q&A_Of_May_20,_2012.txt\n",
      "Chemtrails.txt\n",
      "Q&A_Of_February_22,_2009.txt\n",
      "How_Can_EMFs_Cause_Death_Prematurely?.txt\n",
      "A_New_Theory_Of_Disease.txt\n",
      "Bruises,_Injuries_and_Pain_-_Do_We_Apply_Ice_Or_Heat?.txt\n",
      "Malaria.txt\n",
      "My_Research_And_Experiments_Questioned.txt\n",
      "Q&A_Of_February_18,_2007.txt\n",
      "TB_Testing_for_Teachers_and_Health_Practitioners.txt\n",
      "Primal_Diet_Is_Not_A_Stagnant_Diet.txt\n",
      "Protecting_From_Medical_Treatments_in_Emergencies.txt\n",
      "Care_To_Have_A_Piss_Of_A_Drink_With_Me?.txt\n",
      "Q&A_Of_February_20,_2005.txt\n",
      "Natural_Toys,_Oh,_My!.txt\n",
      "Plastic_consumption_might_lead_to_sexual_disorders.txt\n",
      "Q&A_Of_June_3,_2007.txt\n",
      "Q&A_Of_January_29,_2006.txt\n",
      "At_What_Age_Is_Death_Inevitable?.txt\n",
      "What_Is_Nutrient_Value_Of_Dehydrated_foods?.txt\n",
      "Loss_Of_My_BIOHAZARDS_Research.txt\n",
      "Interview_by_Mina_Olen,_Health_magazine_in_Finland..txt\n",
      "Q&A_Of_January_22,_2000.txt\n",
      "Q&A_Of_May_27,_2012.txt\n",
      "Long-term_Delayed_Detoxification;_58_Years_Later.txt\n",
      "A_Wonderful_Ruling_in_Communist_China_That_We_Should_Adopt.txt\n",
      "Q&A_Of_August_20,_2006.txt\n",
      "Will_We_Continually_Pay_for_Medical_Mass_Poisoning_of_Humanity?.txt\n",
      "More_Clarity_On_Food-borne_Bacterial_Contamination.txt\n",
      "Charlie_Donham_Interview.txt\n",
      "London_Times_Interview.txt\n",
      "Q&A_Of_April_14,_2002.txt\n",
      "Do_We_Believe_Medical_Studies?.txt\n",
      "Frozen_Fish_VS_Frozen_Land_Animals.txt\n",
      "Who_Has_The_Right_To_Institutionalize_Me?.txt\n",
      "Paul_Andrews_Interview.txt\n",
      "Mercury_In_Fish;_Do_We_Absorb_It?.txt\n",
      "Benefits_of_Raw_Eggs.txt\n",
      "Q&A_Of_March_11,_2012.txt\n",
      "Study_Of_Thyroid_Cancer.txt\n",
      "Q&A_Of_September_19,_2000_(Rare).txt\n",
      "Vaccines;_Nice_Shots_Or_Not.txt\n",
      "What_Are_Drugs_And_Supplements?.txt\n",
      "What_Water_Should_I_Buy?.txt\n",
      "Vaccines,_All_Harmful_Or_Some_Beneficial?.txt\n",
      "Are_Citizens_Being_Attacked_By_Their_Governments?.txt\n",
      "What_Is_Our_Likelihood_Of_Developing_Cancer(s)?.txt\n",
      "Q&A_Of_June_10,_2007_&_September_9,_2007.txt\n",
      "Q&A_Of_September_9,_2007.txt\n",
      "Chemicals_Used_to_Protect_Food_From_Bacteria;_Harmful.txt\n",
      "Salt_And_Headaches.txt\n",
      "Human_Papillomavirus_(HPV)_Vaccine.txt\n",
      "Q&A_Of_May_24,_2009.txt\n",
      "Q&A_Of_November_17,_2000.txt\n",
      "Toxic_Chemicals_Out-Gassing_Into_Our_Homes.txt\n",
      "Corporate_&_Government_Tyranny_Behind_Disease.txt\n",
      "Q&A_Of_September_11,_2011.txt\n",
      "Q&A_Of_February_1,_2004.txt\n",
      "Q&A_Of_March_17,_2002.txt\n",
      "Iridology.txt\n",
      "Medications_Are_Toxic_And_Store_In_The_Tissue.txt\n",
      "H1N1_(Swine)_Flu_Epidemic,_Fact_or_Hoax?.txt\n",
      "Q&A_Of_May_30,_2010.txt\n",
      "How_Much_Bacteria_Are_We_Today?.txt\n",
      "LA_Times_Article_About_Raw-Foods.txt\n",
      "Superfoods.txt\n",
      "Why_Mercury_Is_Not_Absorbed_When_We_Eat_Raw_Fish_(Theory).txt\n",
      "Q&A_Of_April_17,_2005.txt\n",
      "Does_Raw_Milk_Do_A_Body_Good?.txt\n",
      "Q&A_Of_July_10,_2011.txt\n",
      "Q&A_Of_November_14,_2004.txt\n",
      "Exercise;_The_Good,_Bad_and_Beautiful.txt\n",
      "How_Much_Energy_Should_I_Expect_To_Experience?.txt\n",
      "Q&A_Of_August_17,_2003_(Full).txt\n",
      "What_Would_Happen_If_Aajonus_Ate_Some_Cooked_Meat?.txt\n",
      "About.txt\n",
      "Eating_Out,_Is_It_Safe?.txt\n",
      "Resolving_Early_Morning_Racing_Mind.txt\n",
      "Medical_Researchers_Proved_90%_Medical_Research_Is_False.txt\n",
      "Fermented_Vegetables;_The_Good,_Bad_and_Stinky.txt\n",
      "Q&A_Of_April_6,_2008.txt\n",
      "Q&A_Of_January_27,_2013.txt\n",
      "Gallbladder_Stones.txt\n",
      "Q&A_Of_July_20,_2008.txt\n",
      "Q&A_Of_May_29,_2011.txt\n",
      "Quality_or_Quantity?.txt\n",
      "Q&A_Of_May_21,_2000_(Rare).txt\n",
      "Q&A_Of_March_19,_2006.txt\n",
      "Grow_In_Height_After_Age_21.txt\n",
      "Q&A_Of_April_11,_2004.txt\n",
      "Pickled_Fish.txt\n",
      "The_Recipe_for_Living_Without_Disease.txt\n",
      "Q&A_Of_February_9,_2003.txt\n",
      "Severe_Back_Deterioration.txt\n",
      "How_To_Use_An_EMF_Meter.txt\n",
      "Interview_on_Talksport.net.txt\n",
      "Q&A_Of_November_27,_2005.txt\n",
      "Q&A_Of_January_9,_2011.txt\n",
      "Depression.txt\n",
      "Home-grown_Vegetables_Blamed_For_Disease.txt\n",
      "Ingredients_In_Injections_With_Hair_And_Iridology_Analyses.txt\n",
      "Q&A_Of_September_12,_2005.txt\n",
      "Dissolving_Plaque_from_Our_Circulatory_Systems.txt\n",
      "Why_Do_Most_Physicians_Refuse_Chemo-treatments?.txt\n",
      "How_Toxic_is_Our_Civilized_World?.txt\n",
      "Child_Cured_by_Mothers_Feces_-_Eat_Shit_and_Live!.txt\n",
      "Oysters_-_Special_Food_In_Our_Toxic_World.txt\n",
      "How_To_Remove_Fear_Of_Microbes.txt\n",
      "Q&A_Of_June_16,_2013.txt\n",
      "Q&A_Of_September_14,_2003.txt\n",
      "How_Do_Electromagnetic_Fields_Affect_Us?.txt\n",
      "Q&A_Of_September_12,_2004.txt\n",
      "What_Is_Nutrient_Value_Trace_Minerals?.txt\n",
      "Q&A_Of_February_25,_2007.txt\n",
      "Will_Big_Industries_Control_Us_via_Government?.txt\n",
      "Considering_Chemotherapy_As_An_Option_For_Cancer?.txt\n",
      "Q&A_Of_July_8,_2001.txt\n",
      "Q&A_Of_August_22,_2011.txt\n",
      "Blood_Types_For_Meat.txt\n",
      "Primal_Diet_Workshop_+_Q&A_Of_June_22,_2013.txt\n",
      "Baby_Food_For_Mothers_Who_Can't_Breastfeed.txt\n",
      "Q&A_Of_July_24,_2005.txt\n",
      "Bacteria,_Antibiotics,_Immune_System.txt\n",
      "Q&A_Of_March_26,_2000.txt\n",
      "Ball_and_Kerr_Jar_Lids,_Are_They_Plastic_Coated_and_Toxic_or_Not?.txt\n",
      "Q&A_Of_June_22,_2003.txt\n",
      "Does_Food_Affect_Behavior?.txt\n",
      "Q&A_Of_November_18,_2007.txt\n",
      "Q&A_Of_April_16,_2006.txt\n",
      "Friendly_Bacteria_Protect_Against_Type_1_Diabetes.txt\n",
      "Are_There_Aggressive_Treatments_For_Cancer?.txt\n",
      "Microbe_Food-Poisoning;_Fact_or_Fiction?.txt\n",
      "Primal_Diet_Workshop_(Part_2).txt\n",
      "What_Place_Do_Energy_Therapies_Take_In_Healing?.txt\n",
      "Chemical_Burns_Can_Be_Devastating_But_Managed_And_Healed.txt\n",
      "E.coli.txt\n",
      "Effects_of_Dietary_and_Environmental_Pollution_on_Children's_Sleep.txt\n",
      "Study_Shows_That_Chubby_People_Live_Longest.txt\n",
      "Q&A_Of_March_18,_2012.txt\n",
      "Oxalates.txt\n",
      "Quick_Alternative_Cure_For_Arthritis;_True_Or_False?.txt\n",
      "Is_It_True_You_Eat_Buckets_Of_Cow_Dung?.txt\n",
      "Can_We_Preserve_Raw_Fish_In_Oil?.txt\n",
      "100%_Of_Fresh-Water_Lakes_And_Streams_Are_Polluted_With_Mercury.txt\n",
      "Q&A_Of_May_7,_2006.txt\n",
      "Non-organic_Meat.txt\n",
      "Coronavirus.txt\n",
      "Repeated_Surgeries_Resulted_In_Thick_Scars.txt\n",
      "Q&A_Of_October_24,_2010.txt\n",
      "Question_And_Answers.txt\n",
      "Man_Eats_Live_Frogs_and_Rats_for_Health.txt\n",
      "Dangers_Of_Salt.txt\n",
      "Iron_On_The_Primal_Diet,_Is_It_A_Problem?.txt\n",
      "Q&A_Of_February_3,_2013.txt\n",
      "Q&A_Of_March_26,_2013.txt\n",
      "FDA_Approves_6_Viruses_As_Safe.txt\n",
      "Beneficial_Home_Baths.txt\n",
      "New_Source_Of_Stem_Cells_-_Mouse_Sperm.txt\n",
      "Athletes_And_Longevity_On_Primal_Diet.txt\n",
      "Q&A_Of_August_17,_2003.txt\n",
      "What_Role_Do_Genetics_and_Microbes_Play_In_Disease?.txt\n",
      "Benzene,_Cancer_and_Soft_Drinks_Connection.txt\n",
      "Primal_Diet_Workshop_(Part_3).txt\n",
      "High_Blood-Pressure.txt\n",
      "Q&A_Of_May_23,_2010.txt\n",
      "Rae_Bradbury_Interview_1.txt\n",
      "Is_It_Good_To_Donate_To_Charities_That_Feed_The_Poor_and_Starving?.txt\n",
      "Q&A_Of_April_4,_2010.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With_Mercury_Found_In_Wild_Animals,_Do_We_Need_To_Be_Extra_Careful?.txt\n",
      "Q&A_Of_September_26,_2010.txt\n",
      "Do_You_Buy_Chicken_While_Traveling?.txt\n",
      "Cancer_Convention_September_2000.txt\n",
      "Q&A_Of_November_7,_1999.txt\n",
      "Q&A_Of_November_26,_2006.txt\n",
      "How_Bad_Are_MRIs?.txt\n",
      "Arsenic_In_Poultry_Meat_And_Eggs.txt\n",
      "Joanne_Unleahsed_Interview.txt\n",
      "Declaring_Our_Rights_To_Our_Body.txt\n",
      "We_Want_To_Live.txt\n",
      "Soy_Toxicity_In_Poultry_Meat_And_Eggs.txt\n",
      "Hot_Tub_Therapy.txt\n",
      "Bacteria_and_Other_Microbes_Are_Responsible_for_Vibrant_Health.txt\n",
      "Gum_And_Tooth_Disease.txt\n",
      "Rae_Bradbury_Interview_2.txt\n",
      "                                            filename  \\\n",
      "0  Needles_Of_Disease_and_Death_Continue_In_The_N...   \n",
      "1  Needles_Of_Disease_and_Death_Continue_In_The_N...   \n",
      "2  Needles_Of_Disease_and_Death_Continue_In_The_N...   \n",
      "3  Needles_Of_Disease_and_Death_Continue_In_The_N...   \n",
      "4  Needles_Of_Disease_and_Death_Continue_In_The_N...   \n",
      "\n",
      "                                            sentence  \n",
      "0  On Halloween, I received the most alarming ter...  \n",
      "1  I received it\\nin a letter from Care2 organiza...  \n",
      "2  Most of us have\\nnever witnessed the crippling...  \n",
      "3  Polio is still endemic in three of the world's...  \n",
      "4  This is the scary truth: levels of polio are a...  \n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = Path.cwd() / \"aajonus_data\"\n",
    "\n",
    "DF_DIR = Path.cwd() / \"aajonus_saved_dfs\"\n",
    "DF_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "df_path = DF_DIR / \"dataframe.csv\"\n",
    "\n",
    "# Conditional that checks whether we saved the dfs as csv files\n",
    "# If yes, then reinitialise these as dfs\n",
    "# If not, then create the dfs and save them in csv format for next run\n",
    "if df_path.exists():\n",
    "    print(\"Loading dataset from CSV...\")\n",
    "    df = pd.read_csv(df_path)\n",
    "else:\n",
    "    data = []\n",
    "\n",
    "    for filename in os.listdir(DATA_DIR):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            print(filename)\n",
    "\n",
    "            # Create the filepath\n",
    "            file_path = DATA_DIR / filename\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                content = file.read()\n",
    "                # Use spaCy to tokenize the content into sentences\n",
    "                doc = nlp(content)\n",
    "                sentences = [sent.text.strip() for sent in doc.sents]\n",
    "                # Append each sentence to your data list, along with the filename\n",
    "                for sentence in sentences:\n",
    "                    data.append({\"filename\": filename, \"sentence\": sentence})\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Save DF\n",
    "    df.to_csv(df_path, index=False)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f929233f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TF-IDF vectorizer to the dataset...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import joblib\n",
    "\n",
    "JOBLIB_DIR = Path.cwd() / \"aajonus_joblibs\"\n",
    "JOBLIB_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "vectorizer_path = JOBLIB_DIR / 'tfidf_vectorizer.joblib'\n",
    "matrix_path = JOBLIB_DIR / 'tfidf_matrix.joblib'\n",
    "\n",
    "max_df = 0.7\n",
    "min_df = 0.00\n",
    "ngram_range = (1, 1)\n",
    "\n",
    "def custom_tokenizer(text):\n",
    "    doc = nlp(text)\n",
    "    return [token.lemma_ for token in doc]\n",
    "\n",
    "# Check if parameters have changed and files exist\n",
    "params_changed = False\n",
    "if vectorizer_path.exists():\n",
    "    existing_vectorizer = joblib.load(vectorizer_path)\n",
    "    if (existing_vectorizer.max_df != max_df or \n",
    "        existing_vectorizer.min_df != min_df or \n",
    "        existing_vectorizer.ngram_range != ngram_range):\n",
    "        params_changed = True\n",
    "        os.remove(vectorizer_path)\n",
    "        os.remove(matrix_path)\n",
    "\n",
    "if not matrix_path.exists() or params_changed:\n",
    "    print(\"Fitting TF-IDF vectorizer to the dataset...\")\n",
    "    vectorizer = TfidfVectorizer(tokenizer=custom_tokenizer, max_df=max_df, min_df=min_df, ngram_range=ngram_range)\n",
    "    tfidf_matrix = vectorizer.fit_transform(df['sentence'])\n",
    "    joblib.dump(vectorizer, vectorizer_path)\n",
    "    joblib.dump(tfidf_matrix, matrix_path)\n",
    "else:\n",
    "    print(\"Loading fitted TF-IDF vectorizer and matrix dataset...\")\n",
    "    vectorizer = joblib.load(vectorizer_path)\n",
    "    tfidf_matrix = joblib.load(matrix_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bd05dc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def search(query, vectorizer, tfidf_matrix, df):\n",
    "    query_vector = vectorizer.transform([query])  # Preprocessing is handled by vectorizer\n",
    "    similarities = cosine_similarity(query_vector, tfidf_matrix)\n",
    "    top_indices = similarities.argsort()[0][-5:]\n",
    "\n",
    "    # Retrieve the corresponding rows from the DataFrame\n",
    "    top_docs = df.iloc[top_indices]\n",
    "    top_scores = similarities[0][top_indices]\n",
    "\n",
    "    return top_docs, top_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a95e0c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "columns=[\"Query\", \"Result\", \"Cosine\", \"Relevance Score\", \"Filename\", \"Date\", \"Max DF\", \"Min DF\", \"Ngram Range\"]\n",
    "\n",
    "def search_main(query, vectorizer, tfidf_matrix, df, max_df, min_df, ngram_range, relevance_feedback):\n",
    "    start_time = time.time()\n",
    "    top_docs, top_scores = search(query, vectorizer, tfidf_matrix, df)\n",
    "    execution_time = time.time() - start_time\n",
    "    \n",
    "    new_rows = []\n",
    "    for index, score in zip(top_docs.index, top_scores):\n",
    "        print(f\"\\n'{query}': '{top_docs.loc[index]['sentence']}', [{score}]\")\n",
    "        row = top_docs.loc[index]\n",
    "        new_rows.append({\n",
    "            \"Query\": query,\n",
    "            \"Result\": row['sentence'],\n",
    "            \"Cosine\": score,\n",
    "            \"Filename\": row['filename'],\n",
    "            \"Relevance Score\": None,\n",
    "            \"Date\": pd.Timestamp('now'),\n",
    "            \"Max DF\": max_df,\n",
    "            \"Min DF\": min_df,\n",
    "            \"Ngram Range\": ngram_range\n",
    "        })\n",
    "\n",
    "    relevance_feedback = pd.concat([relevance_feedback, pd.DataFrame(new_rows)], ignore_index=True)\n",
    "    return relevance_feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "61276110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'Child genius': 'Child.,', [0.4977997821650079]\n",
      "\n",
      "'Child genius': 'Your body is always doing the best it can and\n",
      "it’s a genius.', [0.526598897141908]\n",
      "\n",
      "'Child genius': 'In the children\n",
      "who do not get vaccinations, you got three geniuses out of every ten.', [0.5611802814661668]\n",
      "\n",
      "'Child genius': 'All hyperactive children have potential genius, but unless they can utilize proteins or harness adrenaline, their genius may turn into antisocial behavior.', [0.588753449079798]\n",
      "\n",
      "'Child genius': 'The child is absolutely a genius.', [0.8416843240422897]\n"
     ]
    }
   ],
   "source": [
    "FEEDBACK_DIR = Path.cwd() / \"aajonus_feedback\"\n",
    "FEEDBACK_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "def get_feedback_df(feedback_path):\n",
    "    if feedback_path.exists():\n",
    "        df = pd.read_csv(feedback_path)\n",
    "        df['Date'] = pd.to_datetime(df['Date'])  # Convert to datetime\n",
    "        return df\n",
    "    else:\n",
    "        return pd.DataFrame(columns=columns)\n",
    "\n",
    "feedback_path = FEEDBACK_DIR / \"relevance_feedback.csv\"\n",
    "relevance_feedback = get_feedback_df(feedback_path)\n",
    "\n",
    "query = \"Child genius\"\n",
    "relevance_feedback = search_main(query, vectorizer, tfidf_matrix, df, max_df, min_df, ngram_range, relevance_feedback)\n",
    "\n",
    "# Save updated DataFrame\n",
    "relevance_feedback.to_csv(feedback_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae5b34a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
