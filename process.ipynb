{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6084335a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /Users/ethancavill/anaconda3/lib/python3.11/site-packages (from en-core-web-sm==3.5.0) (3.5.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/ethancavill/anaconda3/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/ethancavill/anaconda3/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/ethancavill/anaconda3/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.7)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/ethancavill/anaconda3/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.6)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/ethancavill/anaconda3/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.6)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /Users/ethancavill/anaconda3/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.12)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/ethancavill/anaconda3/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.9.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/ethancavill/anaconda3/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/ethancavill/anaconda3/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.10)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /Users/ethancavill/anaconda3/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.9.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /Users/ethancavill/anaconda3/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/ethancavill/anaconda3/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/ethancavill/anaconda3/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/ethancavill/anaconda3/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.24.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/ethancavill/anaconda3/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /Users/ethancavill/anaconda3/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.12)\n",
      "Requirement already satisfied: jinja2 in /Users/ethancavill/anaconda3/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /Users/ethancavill/anaconda3/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (68.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/ethancavill/anaconda3/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/ethancavill/anaconda3/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/ethancavill/anaconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ethancavill/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ethancavill/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ethancavill/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ethancavill/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2023.7.22)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/ethancavill/anaconda3/lib/python3.11/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/ethancavill/anaconda3/lib/python3.11/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.1.3)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/ethancavill/anaconda3/lib/python3.11/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/ethancavill/anaconda3/lib/python3.11/site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "spacy.cli.download(\"en_core_web_sm\")\n",
    "# python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e05e501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.pipeline.sentencizer.Sentencizer at 0x168b92c10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\", \"parser\"])\n",
    "nlp.add_pipe(\"sentencizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3eb4f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Needles_Of_Disease_and_Death_Continue_In_The_Name_Of_Saving_Children.txt\n",
      "Diarrhea-based_Detoxification_Hotel_By_Medical_Doctors.txt\n",
      "The_FDA_Approved_5_Viruses_for_Food_Treatment.txt\n",
      "Genius_Children.txt\n",
      "Dr._Stanley_S._Bass_Interview.txt\n",
      "Q&A_Of_September_13,_2009.txt\n",
      "Causes_For_Most_Intestinal_Disease.txt\n",
      "Are_Raw_Miso_And_Shoyu_Healthy_Sauces?.txt\n",
      "Safe_Cutting_Boards.txt\n",
      "Multiple_Lacerations_Healed_Without_Medical_Help.txt\n",
      "Cholesterol,_LDL_and_HDL.txt\n",
      "Primal_Diet_Workshop_+_Q&A_Of_May_6,_2000.txt\n",
      "Can_We_Preserve_Raw_Chicken_In_Vinegar_Or_Lemon_Juice?.txt\n",
      "Abrasions,_Fractures_and_Breaks.txt\n",
      "Is_Raw_Chocolate_Made_From_Whole_Raw_Cocoa_Beans_Addictive_Or_Harmful?.txt\n",
      "What_Is_Constipation_And_How_Do_We_Resolve_It?.txt\n",
      "Our_Ubiquitous_Microbial_Friends.txt\n",
      "Quinton.txt\n",
      "Q&A_Of_December_14,_2008.txt\n",
      "Q&A_Of_October_14,_2012.txt\n",
      "My_Survival_Kit.txt\n",
      "Medical_Propaganda_about_Inflammatory_Breast_Cancer.txt\n",
      "How_Are_Nutrients_Delivered_To_Our_Cells?.txt\n",
      "Q&A_Of_August_24,_2008.txt\n",
      "Vaccines_Ruin_Your_Health.txt\n",
      "Frozen_Pastured_Meat_VS_Fresh_Supermarket_Meat.txt\n",
      "Long-term_Damage_From_Abduction_and_Forced_Injections.txt\n",
      "Q&A_Of_May_26,_2013.txt\n",
      "FLU_-_Viral_Tools_Improve_Health.txt\n",
      "Email_from_Aajonus_Summer_2012.txt\n",
      "Dental_Hygiene,_Causes_of_Decay_and_Reversal,_and_Re-enamelization.txt\n",
      "Bad_And_Good_Parasites,_And_Malaria?.txt\n",
      "View_on_Medical_Establishment.txt\n",
      "Formula_for_a_Healthy_Baby.txt\n",
      "Top_Aussie_Doctor_Says_Pick_Your_Nose_And_Eat_it.txt\n",
      "Supplements.txt\n",
      "Primal_Diet_Workshop_(Part_1).txt\n",
      "Raw_Dairy_Is_Healthy_But_Illegal.txt\n",
      "Does_Rabies_Exist?.txt\n",
      "Q&A_Of_May_2,_2004.txt\n",
      "Abduction_and_Injections.txt\n",
      "Is_Raw_Milk_Always_Beneficial_Even_With_Much_Bacteria?.txt\n",
      "Q&A_Of_September_10,_2006.txt\n",
      "How_Long_Does_It_Take_To_Understand_The_Primal_Diet(TM)?.txt\n",
      "Rawesome_Trial_Outcome.txt\n",
      "Q&A_Of_June_29,_2008.txt\n",
      "Whole_Foods_Markets,_Inc._Friend_To_Better_Health_Or_Foe?.txt\n",
      "Q&A_Of_December_17,_2006.txt\n",
      "What_Should_We_Consider_For_Health_When_Buying_A_New_Car?.txt\n",
      "Q&A_Of_January_24,_1999.txt\n",
      "Lobbying_in_Washington,_DC_for_Raw_Milk.txt\n",
      "What_Do_We_Do_About_Emerging_Plagues?.txt\n",
      "Is_The_Science_of_Viruses_Real?.txt\n",
      "Q&A_Of_May_20,_2012.txt\n",
      "Chemtrails.txt\n",
      "Q&A_Of_February_22,_2009.txt\n",
      "How_Can_EMFs_Cause_Death_Prematurely?.txt\n",
      "A_New_Theory_Of_Disease.txt\n",
      "Bruises,_Injuries_and_Pain_-_Do_We_Apply_Ice_Or_Heat?.txt\n",
      "Malaria.txt\n",
      "My_Research_And_Experiments_Questioned.txt\n",
      "Q&A_Of_February_18,_2007.txt\n",
      "TB_Testing_for_Teachers_and_Health_Practitioners.txt\n",
      "Primal_Diet_Is_Not_A_Stagnant_Diet.txt\n",
      "Protecting_From_Medical_Treatments_in_Emergencies.txt\n",
      "Care_To_Have_A_Piss_Of_A_Drink_With_Me?.txt\n",
      "Q&A_Of_February_20,_2005.txt\n",
      "Natural_Toys,_Oh,_My!.txt\n",
      "Plastic_consumption_might_lead_to_sexual_disorders.txt\n",
      "Q&A_Of_June_3,_2007.txt\n",
      "Q&A_Of_January_29,_2006.txt\n",
      "At_What_Age_Is_Death_Inevitable?.txt\n",
      "What_Is_Nutrient_Value_Of_Dehydrated_foods?.txt\n",
      "Loss_Of_My_BIOHAZARDS_Research.txt\n",
      "Interview_by_Mina_Olen,_Health_magazine_in_Finland..txt\n",
      "Q&A_Of_January_22,_2000.txt\n",
      "Q&A_Of_May_27,_2012.txt\n",
      "Long-term_Delayed_Detoxification;_58_Years_Later.txt\n",
      "A_Wonderful_Ruling_in_Communist_China_That_We_Should_Adopt.txt\n",
      "Q&A_Of_August_20,_2006.txt\n",
      "Will_We_Continually_Pay_for_Medical_Mass_Poisoning_of_Humanity?.txt\n",
      "More_Clarity_On_Food-borne_Bacterial_Contamination.txt\n",
      "Charlie_Donham_Interview.txt\n",
      "London_Times_Interview.txt\n",
      "Q&A_Of_April_14,_2002.txt\n",
      "Do_We_Believe_Medical_Studies?.txt\n",
      "Frozen_Fish_VS_Frozen_Land_Animals.txt\n",
      "Who_Has_The_Right_To_Institutionalize_Me?.txt\n",
      "Paul_Andrews_Interview.txt\n",
      "Mercury_In_Fish;_Do_We_Absorb_It?.txt\n",
      "Benefits_of_Raw_Eggs.txt\n",
      "Q&A_Of_March_11,_2012.txt\n",
      "Study_Of_Thyroid_Cancer.txt\n",
      "Q&A_Of_September_19,_2000_(Rare).txt\n",
      "Vaccines;_Nice_Shots_Or_Not.txt\n",
      "What_Are_Drugs_And_Supplements?.txt\n",
      "What_Water_Should_I_Buy?.txt\n",
      "Vaccines,_All_Harmful_Or_Some_Beneficial?.txt\n",
      "Are_Citizens_Being_Attacked_By_Their_Governments?.txt\n",
      "What_Is_Our_Likelihood_Of_Developing_Cancer(s)?.txt\n",
      "Q&A_Of_June_10,_2007_&_September_9,_2007.txt\n",
      "Q&A_Of_September_9,_2007.txt\n",
      "Chemicals_Used_to_Protect_Food_From_Bacteria;_Harmful.txt\n",
      "Salt_And_Headaches.txt\n",
      "Human_Papillomavirus_(HPV)_Vaccine.txt\n",
      "Q&A_Of_May_24,_2009.txt\n",
      "Q&A_Of_November_17,_2000.txt\n",
      "Toxic_Chemicals_Out-Gassing_Into_Our_Homes.txt\n",
      "Corporate_&_Government_Tyranny_Behind_Disease.txt\n",
      "Q&A_Of_September_11,_2011.txt\n",
      "Q&A_Of_February_1,_2004.txt\n",
      "Q&A_Of_March_17,_2002.txt\n",
      "Iridology.txt\n",
      "Medications_Are_Toxic_And_Store_In_The_Tissue.txt\n",
      "H1N1_(Swine)_Flu_Epidemic,_Fact_or_Hoax?.txt\n",
      "Q&A_Of_May_30,_2010.txt\n",
      "How_Much_Bacteria_Are_We_Today?.txt\n",
      "LA_Times_Article_About_Raw-Foods.txt\n",
      "Superfoods.txt\n",
      "Why_Mercury_Is_Not_Absorbed_When_We_Eat_Raw_Fish_(Theory).txt\n",
      "Q&A_Of_April_17,_2005.txt\n",
      "Does_Raw_Milk_Do_A_Body_Good?.txt\n",
      "Q&A_Of_July_10,_2011.txt\n",
      "Q&A_Of_November_14,_2004.txt\n",
      "Exercise;_The_Good,_Bad_and_Beautiful.txt\n",
      "How_Much_Energy_Should_I_Expect_To_Experience?.txt\n",
      "Q&A_Of_August_17,_2003_(Full).txt\n",
      "What_Would_Happen_If_Aajonus_Ate_Some_Cooked_Meat?.txt\n",
      "About.txt\n",
      "Eating_Out,_Is_It_Safe?.txt\n",
      "Resolving_Early_Morning_Racing_Mind.txt\n",
      "Medical_Researchers_Proved_90%_Medical_Research_Is_False.txt\n",
      "Fermented_Vegetables;_The_Good,_Bad_and_Stinky.txt\n",
      "Q&A_Of_April_6,_2008.txt\n",
      "Q&A_Of_January_27,_2013.txt\n",
      "Gallbladder_Stones.txt\n",
      "Q&A_Of_July_20,_2008.txt\n",
      "Q&A_Of_May_29,_2011.txt\n",
      "Quality_or_Quantity?.txt\n",
      "Q&A_Of_May_21,_2000_(Rare).txt\n",
      "Q&A_Of_March_19,_2006.txt\n",
      "Grow_In_Height_After_Age_21.txt\n",
      "Q&A_Of_April_11,_2004.txt\n",
      "Pickled_Fish.txt\n",
      "The_Recipe_for_Living_Without_Disease.txt\n",
      "Q&A_Of_February_9,_2003.txt\n",
      "Severe_Back_Deterioration.txt\n",
      "How_To_Use_An_EMF_Meter.txt\n",
      "Interview_on_Talksport.net.txt\n",
      "Q&A_Of_November_27,_2005.txt\n",
      "Q&A_Of_January_9,_2011.txt\n",
      "Depression.txt\n",
      "Home-grown_Vegetables_Blamed_For_Disease.txt\n",
      "Ingredients_In_Injections_With_Hair_And_Iridology_Analyses.txt\n",
      "Q&A_Of_September_12,_2005.txt\n",
      "Dissolving_Plaque_from_Our_Circulatory_Systems.txt\n",
      "Why_Do_Most_Physicians_Refuse_Chemo-treatments?.txt\n",
      "How_Toxic_is_Our_Civilized_World?.txt\n",
      "Child_Cured_by_Mothers_Feces_-_Eat_Shit_and_Live!.txt\n",
      "Oysters_-_Special_Food_In_Our_Toxic_World.txt\n",
      "How_To_Remove_Fear_Of_Microbes.txt\n",
      "Q&A_Of_June_16,_2013.txt\n",
      "Q&A_Of_September_14,_2003.txt\n",
      "How_Do_Electromagnetic_Fields_Affect_Us?.txt\n",
      "Q&A_Of_September_12,_2004.txt\n",
      "What_Is_Nutrient_Value_Trace_Minerals?.txt\n",
      "Q&A_Of_February_25,_2007.txt\n",
      "Will_Big_Industries_Control_Us_via_Government?.txt\n",
      "Considering_Chemotherapy_As_An_Option_For_Cancer?.txt\n",
      "Q&A_Of_July_8,_2001.txt\n",
      "Q&A_Of_August_22,_2011.txt\n",
      "Blood_Types_For_Meat.txt\n",
      "Primal_Diet_Workshop_+_Q&A_Of_June_22,_2013.txt\n",
      "Baby_Food_For_Mothers_Who_Can't_Breastfeed.txt\n",
      "Q&A_Of_July_24,_2005.txt\n",
      "Bacteria,_Antibiotics,_Immune_System.txt\n",
      "Q&A_Of_March_26,_2000.txt\n",
      "Ball_and_Kerr_Jar_Lids,_Are_They_Plastic_Coated_and_Toxic_or_Not?.txt\n",
      "Q&A_Of_June_22,_2003.txt\n",
      "Does_Food_Affect_Behavior?.txt\n",
      "Q&A_Of_November_18,_2007.txt\n",
      "Q&A_Of_April_16,_2006.txt\n",
      "Friendly_Bacteria_Protect_Against_Type_1_Diabetes.txt\n",
      "Are_There_Aggressive_Treatments_For_Cancer?.txt\n",
      "Microbe_Food-Poisoning;_Fact_or_Fiction?.txt\n",
      "Primal_Diet_Workshop_(Part_2).txt\n",
      "What_Place_Do_Energy_Therapies_Take_In_Healing?.txt\n",
      "Chemical_Burns_Can_Be_Devastating_But_Managed_And_Healed.txt\n",
      "E.coli.txt\n",
      "Effects_of_Dietary_and_Environmental_Pollution_on_Children's_Sleep.txt\n",
      "Study_Shows_That_Chubby_People_Live_Longest.txt\n",
      "Q&A_Of_March_18,_2012.txt\n",
      "Oxalates.txt\n",
      "Quick_Alternative_Cure_For_Arthritis;_True_Or_False?.txt\n",
      "Is_It_True_You_Eat_Buckets_Of_Cow_Dung?.txt\n",
      "Can_We_Preserve_Raw_Fish_In_Oil?.txt\n",
      "100%_Of_Fresh-Water_Lakes_And_Streams_Are_Polluted_With_Mercury.txt\n",
      "Q&A_Of_May_7,_2006.txt\n",
      "Non-organic_Meat.txt\n",
      "Coronavirus.txt\n",
      "Repeated_Surgeries_Resulted_In_Thick_Scars.txt\n",
      "Q&A_Of_October_24,_2010.txt\n",
      "Question_And_Answers.txt\n",
      "Man_Eats_Live_Frogs_and_Rats_for_Health.txt\n",
      "Dangers_Of_Salt.txt\n",
      "Iron_On_The_Primal_Diet,_Is_It_A_Problem?.txt\n",
      "Q&A_Of_February_3,_2013.txt\n",
      "Q&A_Of_March_26,_2013.txt\n",
      "FDA_Approves_6_Viruses_As_Safe.txt\n",
      "Beneficial_Home_Baths.txt\n",
      "New_Source_Of_Stem_Cells_-_Mouse_Sperm.txt\n",
      "Athletes_And_Longevity_On_Primal_Diet.txt\n",
      "Q&A_Of_August_17,_2003.txt\n",
      "What_Role_Do_Genetics_and_Microbes_Play_In_Disease?.txt\n",
      "Benzene,_Cancer_and_Soft_Drinks_Connection.txt\n",
      "Primal_Diet_Workshop_(Part_3).txt\n",
      "High_Blood-Pressure.txt\n",
      "Q&A_Of_May_23,_2010.txt\n",
      "Rae_Bradbury_Interview_1.txt\n",
      "Is_It_Good_To_Donate_To_Charities_That_Feed_The_Poor_and_Starving?.txt\n",
      "Q&A_Of_April_4,_2010.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With_Mercury_Found_In_Wild_Animals,_Do_We_Need_To_Be_Extra_Careful?.txt\n",
      "Q&A_Of_September_26,_2010.txt\n",
      "Do_You_Buy_Chicken_While_Traveling?.txt\n",
      "Cancer_Convention_September_2000.txt\n",
      "Q&A_Of_November_7,_1999.txt\n",
      "Q&A_Of_November_26,_2006.txt\n",
      "How_Bad_Are_MRIs?.txt\n",
      "Arsenic_In_Poultry_Meat_And_Eggs.txt\n",
      "Joanne_Unleahsed_Interview.txt\n",
      "Declaring_Our_Rights_To_Our_Body.txt\n",
      "We_Want_To_Live.txt\n",
      "Soy_Toxicity_In_Poultry_Meat_And_Eggs.txt\n",
      "Hot_Tub_Therapy.txt\n",
      "Bacteria_and_Other_Microbes_Are_Responsible_for_Vibrant_Health.txt\n",
      "Gum_And_Tooth_Disease.txt\n",
      "Rae_Bradbury_Interview_2.txt\n",
      "                                            filename  \\\n",
      "0  Needles_Of_Disease_and_Death_Continue_In_The_N...   \n",
      "1  Needles_Of_Disease_and_Death_Continue_In_The_N...   \n",
      "2  Needles_Of_Disease_and_Death_Continue_In_The_N...   \n",
      "3  Needles_Of_Disease_and_Death_Continue_In_The_N...   \n",
      "4  Needles_Of_Disease_and_Death_Continue_In_The_N...   \n",
      "\n",
      "                                            sentence  \n",
      "0  On Halloween, I received the most alarming ter...  \n",
      "1  I received it\\nin a letter from Care2 organiza...  \n",
      "2  Most of us have\\nnever witnessed the crippling...  \n",
      "3  Polio is still endemic in three of the world's...  \n",
      "4  This is the scary truth: levels of polio are a...  \n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = Path.cwd() / \"aajonus_data\"\n",
    "\n",
    "DF_DIR = Path.cwd() / \"aajonus_saved_dfs\"\n",
    "DF_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "full_df = DF_DIR / \"full_dataframe.csv\"\n",
    "\n",
    "# Conditional that checks whether we saved the dfs as csv files\n",
    "# If yes, then reinitialise these as dfs\n",
    "# If not, then create the dfs and save them in csv format for next run\n",
    "if full_df.exists():\n",
    "    print(\"Loading full dataset from CSV...\")\n",
    "    df = pd.read_csv(full_df)\n",
    "else:\n",
    "    data = []\n",
    "\n",
    "    for filename in os.listdir(DATA_DIR):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            print(filename)\n",
    "\n",
    "            # Create the full filepath\n",
    "            file_path = os.path.join(DATA_DIR, filename)\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                content = file.read()\n",
    "                # Use spaCy to tokenize the content into sentences\n",
    "                doc = nlp(content)\n",
    "                sentences = [sent.text.strip() for sent in doc.sents]\n",
    "                # Append each sentence to your data list, along with the filename\n",
    "                for sentence in sentences:\n",
    "                    data.append({\"filename\": filename, \"sentence\": sentence})\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Save DF\n",
    "    df.to_csv(full_df, index=False)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c62fa77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           filename  \\\n",
      "2005  Primal_Diet_Workshop_+_Q&A_Of_May_6,_2000.txt   \n",
      "2006  Primal_Diet_Workshop_+_Q&A_Of_May_6,_2000.txt   \n",
      "2007  Primal_Diet_Workshop_+_Q&A_Of_May_6,_2000.txt   \n",
      "2008  Primal_Diet_Workshop_+_Q&A_Of_May_6,_2000.txt   \n",
      "2009  Primal_Diet_Workshop_+_Q&A_Of_May_6,_2000.txt   \n",
      "\n",
      "                                               sentence  \n",
      "2005  @Source\\n\\nTranscriber: Michael - Thank you, M...  \n",
      "2006  Primal Diet Workshop in Nevada City, Californi...  \n",
      "2007  He's here to talk to us\\nabout raw food, about...  \n",
      "2008  Aajonus came into our\\nlives a couple of years...  \n",
      "2009                                  Thank you Jill. [  \n"
     ]
    }
   ],
   "source": [
    "test_set_csv = Path.cwd() / \"aajonus_test_set_data\" / \"aajonus_test_set_data.csv\"\n",
    "test_df = DF_DIR / \"test_dataframe.csv\"\n",
    "\n",
    "if test_df.exists():\n",
    "    print(\"Loading test dataset from CSV...\")\n",
    "    test_set_df = pd.read_csv(test_df)\n",
    "else:\n",
    "    test_set_df = pd.read_csv(test_set_csv)\n",
    "\n",
    "    unique_filenames = test_set_df['Filename'].unique()\n",
    "    test_set_df = df[df['filename'].isin(unique_filenames)]\n",
    "\n",
    "    test_set_df.to_csv(test_df, index=False)\n",
    "\n",
    "print(test_set_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95247a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_lemmatize(text):\n",
    "    text = text.lower()\n",
    "\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    lemmas = [token.lemma_ for token in doc]\n",
    "    \n",
    "    return ' '.join(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0278fe3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['expanded_lemmatized_text'] = df['sentence'].apply(spacy_lemmatize)\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f929233f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize the vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the preprocessed text\n",
    "tfidf_matrix = vectorizer.fit_transform(df['expanded_lemmatized_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937a4579",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib_dir = Path.cwd() / \"aajonus_joblibs\"\n",
    "joblib_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Define the full path for the vectorizer and matrix joblib files\n",
    "vectorizer_path = joblib_dir / 'tfidf_vectorizer.joblib'\n",
    "matrix_path = joblib_dir / 'tfidf_matrix.joblib'\n",
    "\n",
    "# Save the vectorizer and matrix to disk in the specified directory\n",
    "joblib.dump(vectorizer, vectorizer_path)\n",
    "joblib.dump(tfidf_matrix, matrix_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd05dc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def search(query, vectorizer, tfidf_matrix, df):\n",
    "    # Preprocess the query\n",
    "    preprocessed_query = spacy_lemmatize(query)\n",
    "    \n",
    "    # Vectorize the query\n",
    "    query_vector = vectorizer.transform([preprocessed_query])\n",
    "    \n",
    "    # Compute cosine similarity between the query and the documents\n",
    "    similarities = cosine_similarity(query_vector, tfidf_matrix)\n",
    "    \n",
    "    # Get the top 5 most similar document indices\n",
    "    top_indices = similarities.argsort()[0][-10:]\n",
    "    \n",
    "    # Return the most similar documents and their similarity scores\n",
    "    return df.iloc[top_indices], similarities[0][top_indices]\n",
    "\n",
    "# Test the search with an example query\n",
    "example_query = \"high meat\"\n",
    "top_docs, scores = search(example_query, vectorizer, tfidf_matrix, df)\n",
    "print(top_docs)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dba6b47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61276110",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Updated DataFrame with additional columns\n",
    "hyperparameter_results = pd.DataFrame(columns=[\n",
    "    \"Date\", \n",
    "    \"Dataset Characteristics\", \n",
    "    \"Max DF\", \n",
    "    \"Min DF\", \n",
    "    \"Ngram Range\", \n",
    "    \"Precision\", \n",
    "    \"Recall\", \n",
    "    \"F1-Score\", \n",
    "    \"Execution Time\", \n",
    "    \"Threshold\", \n",
    "    \"Comments\", \n",
    "    \"Example Queries & Results\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae5b34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of how to add data to the DataFrame\n",
    "# hyperparameter_results.loc[len(hyperparameter_results)] = [\"2023-05-01\", \"Technical domain texts\", 0.95, 0.01, (1,2), 0.8, 0.7, 0.77, \"30s\", 0.5, \"First trial run\", \"query1 -> Doc A, B, C\"]\n",
    "\n",
    "# Saving the DataFrame as a CSV file\n",
    "hyperparameter_results.to_csv(\"hyperparameter_results.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
